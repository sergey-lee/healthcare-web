#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
–î–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –≤—Å–µ—Ö —Ç–µ–∫—Å—Ç–æ–≤ –ø—Ä–æ–µ–∫—Ç–∞
–°–æ–∑–¥–∞–µ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∫–∞—Ç–∞–ª–æ–≥ —Å –∫–∞—Ç–µ–≥–æ—Ä–∏–∑–∞—Ü–∏–µ–π
"""

import json
from collections import defaultdict

def load_data():
    """–ó–∞–≥—Ä—É–∑–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö"""
    with open('extracted-texts.json', 'r', encoding='utf-8') as f:
        return json.load(f)

def analyze_korean_texts(data):
    """–î–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –∫–æ—Ä–µ–π—Å–∫–∏—Ö —Ç–µ–∫—Å—Ç–æ–≤"""
    korean = data.get('korean', {})

    catalog = {
        'navigation': [],
        'footer': [],
        'history': [],
        'overview': [],
        'projects': [],
        'faq': [],
        'location': [],
        'research': [],
        'news': [],
        'gallery': [],
        'contact': [],
        'buttons': [],
        'forms': [],
        'meta': [],
        'uncategorized': []
    }

    # –ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –¥–ª—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∑–∞—Ü–∏–∏
    keywords = {
        'navigation': ['Ïó∞Íµ¨Î∞èÍ∞úÎ∞ú', 'Í≥†Í∞ùÏßÄÏõê', 'ÌöåÏÇ¨ÏÜåÍ∞ú', 'FAQ', 'Inquiry', 'Overview', 'History', 'Development'],
        'footer': ['ÏÉÅÌò∏', 'ÎåÄÌëúÎ™Ö', 'Ï£ºÏÜå', 'Ï†ÑÌôîÎ≤àÌò∏', 'ÏÇ¨ÏóÖÏûêÎì±Î°ùÎ≤àÌò∏', 'Ìå©Ïä§', 'ÎîîÌéÑÏä§', 'DiagnoX'],
        'history': ['ÏÑ§Î¶Ω', 'Ïó∞Íµ¨ÏÑ±Í≥º', 'Í∏ÄÎ°úÎ≤å ÌòëÎ†•', 'AI Í∏∞Î∞ò', 'ÏßÄÏÜç Í∞ÄÎä•', 'Í±¥Í∞ïÏùòÌïôÏó∞Íµ¨ÏÑºÌÑ∞ ÏÑ§Î¶Ω', 'Ïù∏ÌîÑÎùº Íµ¨Ï∂ï'],
        'overview': ['ÏùòÎ£åÏôÄ Í∏∞Ïà†', 'Í±¥Í∞ï ÌòÅÏã†', 'Í±¥Í∞ïÌïú ÏÇ∂', 'ÎπÑÏ†Ñ', 'Î°úÍ≥†', 'Í±¥Í∞ïÏùòÌïôÏó∞Íµ¨ÏÑºÌÑ∞Î•º Ï∞æÏïÑÏ£ºÏã†'],
        'projects': ['Project', 'ÏùòÎ£åÍ∏∞Í¥Ä', 'Ïó∞Íµ¨ÏÜå', 'Í∞úÏù∏ Í±¥Í∞ï Í¥ÄÎ¶¨', 'Î®∏Ïã†Îü¨Îãù', 'Îç∞Ïù¥ÌÑ∞ Ï≤òÎ¶¨', 'Ìó¨Ïä§ÌÖåÌÅ¨'],
        'faq': ['ÏßàÎ¨∏', 'ÎãµÎ≥Ä', 'FAQ', 'ÏûêÏ£º Î¨ªÎäî'],
        'location': ['Î≥∏ÏÇ¨', 'Ïó∞Íµ¨ÏÜå ÏïàÎÇ¥', 'ÏúÑÏπò', 'Ï£ºÏÜå', 'Ïò§ÏãúÎäî Í∏∏'],
        'research': ['Ïó∞Íµ¨', 'Í∞úÎ∞ú', 'R&D', 'Í∏∞Ïà†', 'ÌòÅÏã†', 'Îç∞Ïù¥ÌÑ∞ Î∂ÑÏÑù'],
        'news': ['Ïã†Ï†úÌíà Ï∂úÏãú', 'Î≥∏ÏÇ¨ Ïù¥Ï†Ñ', 'Ï∂îÏÑù Ïó∞Ìú¥', 'ÏÑúÎ≤Ñ Ï†êÍ≤Ä', 'Ïù¥Î≤§Ìä∏', 'ÏïàÎÇ¥'],
        'gallery': ['Í∞§Îü¨Î¶¨', 'ÏÇ¨ÏßÑ', 'Ïù¥ÎØ∏ÏßÄ'],
        'contact': ['Î¨∏Ïùò', 'Ïó∞ÎùΩ', 'Ïù¥Î©îÏùº', 'Ï†ÑÌôî'],
        'buttons': ['Í≤ÄÏÉâ', 'Ï†úÏ∂ú', 'Î≥¥ÎÇ¥Í∏∞', 'ÌôïÏù∏'],
        'forms': ['Ïù¥Î¶Ñ', 'Ï†ÑÌôî', 'Ïù¥Î©îÏùº', 'Î©îÏãúÏßÄ', 'ÎÇ¥Ïö©'],
    }

    # –û–±—Ä–∞–±–æ—Ç–∫–∞ –≤—Å–µ—Ö —Ç–∏–ø–æ–≤ —Ç–µ–∫—Å—Ç–æ–≤
    for text_type, texts in korean.items():
        for item in texts:
            text = item['text']
            context = item['context']
            files = item['files']

            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏—é
            category = 'uncategorized'

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º
            for cat, words in keywords.items():
                if any(word in text for word in words):
                    category = cat
                    break

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ –ø—É—Ç—è–º —Ñ–∞–π–ª–æ–≤
            if category == 'uncategorized':
                file_str = ' '.join(str(f) for f in files).lower()
                if 'history' in file_str:
                    category = 'history'
                elif 'intro' in file_str or 'overview' in file_str:
                    category = 'overview'
                elif 'portfolio' in file_str or 'project' in file_str:
                    category = 'projects'
                elif 'faq' in file_str:
                    category = 'faq'
                elif 'location' in file_str:
                    category = 'location'
                elif 'research' in file_str or 'development' in file_str:
                    category = 'research'
                elif 'news' in file_str or 'post-news' in file_str:
                    category = 'news'
                elif 'gallery' in file_str:
                    category = 'gallery'
                elif 'contact' in file_str or 'inquiry' in file_str:
                    category = 'contact'

            # –°–ø–µ—Ü–∏–∞–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–ª—è footer
            if len(files) > 50:  # –ï—Å–ª–∏ —Ç–µ–∫—Å—Ç –≤—Å—Ç—Ä–µ—á–∞–µ—Ç—Å—è –≤ –±–æ–ª—å—à–∏–Ω—Å—Ç–≤–µ —Ñ–∞–π–ª–æ–≤
                category = 'footer'

            # –î–æ–±–∞–≤–ª—è–µ–º –≤ –∫–∞—Ç–∞–ª–æ–≥
            catalog[category].append({
                'text': text,
                'type': text_type,
                'context': context,
                'count': len(files),
                'files': files[:3]  # –¢–æ–ª—å–∫–æ –ø–µ—Ä–≤—ã–µ 3 —Ñ–∞–π–ª–∞ –¥–ª—è –ø—Ä–∏–º–µ—Ä–∞
            })

    return catalog

def generate_markdown_report(catalog, korean_data):
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–∞ –≤ —Ñ–æ—Ä–º–∞—Ç–µ Markdown"""

    report = """# –ü–æ–ª–Ω—ã–π –∫–∞—Ç–∞–ª–æ–≥ —Ç–µ–∫—Å—Ç–æ–≤ –ø—Ä–æ–µ–∫—Ç–∞ Healthcare Web

## –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞

"""

    # –ü–æ–¥—Å—á–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
    total = 0
    for cat, items in catalog.items():
        count = len(items)
        total += count
        if count > 0:
            report += f"- **{cat.upper()}**: {count} —Ç–µ–∫—Å—Ç–æ–≤\n"

    report += f"\n**–í–°–ï–ì–û**: {total} —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∫–æ—Ä–µ–π—Å–∫–∏—Ö —Ç–µ–∫—Å—Ç–æ–≤\n\n"
    report += "---\n\n"

    # –î–µ—Ç–∞–ª—å–Ω—ã–π –∫–∞—Ç–∞–ª–æ–≥ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º
    for category, items in catalog.items():
        if not items:
            continue

        report += f"## {category.upper()}\n\n"
        report += f"–í—Å–µ–≥–æ —Ç–µ–∫—Å—Ç–æ–≤: {len(items)}\n\n"

        # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ —Ç–∏–ø—É
        by_type = defaultdict(list)
        for item in items:
            by_type[item['type']].append(item)

        for text_type, type_items in sorted(by_type.items()):
            report += f"### {text_type.capitalize()}\n\n"

            for item in type_items:
                report += f"#### `{item['text'][:100]}{'...' if len(item['text']) > 100 else ''}`\n\n"
                report += f"- **–ö–æ–Ω—Ç–µ–∫—Å—Ç**: `{item['context']}`\n"
                report += f"- **–í—Å—Ç—Ä–µ—á–∞–µ—Ç—Å—è**: {item['count']} —Ä–∞–∑\n"
                report += f"- **–ü—Ä–∏–º–µ—Ä—ã —Ñ–∞–π–ª–æ–≤**:\n"
                for f in item['files']:
                    filename = f.split('/')[-1]
                    report += f"  - {filename}\n"
                report += "\n"

        report += "---\n\n"

    return report

def generate_csv_catalog(catalog):
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∫–∞—Ç–∞–ª–æ–≥–∞ –≤ —Ñ–æ—Ä–º–∞—Ç–µ CSV"""
    csv_lines = ["Category,Type,Text,Context,Count,Example Files"]

    for category, items in catalog.items():
        for item in items:
            text = item['text'].replace('"', '""')  # Escape quotes
            files = '; '.join(f.split('/')[-1] for f in item['files'])
            csv_lines.append(f'"{category}","{item["type"]}","{text}","{item["context"]}",{item["count"]},"{files}"')

    return '\n'.join(csv_lines)

def main():
    print("üìö –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö...")
    data = load_data()

    print("üîç –ê–Ω–∞–ª–∏–∑ –∫–æ—Ä–µ–π—Å–∫–∏—Ö —Ç–µ–∫—Å—Ç–æ–≤...")
    catalog = analyze_korean_texts(data)

    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    print("\nüìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º:")
    total = 0
    for cat, items in sorted(catalog.items()):
        count = len(items)
        total += count
        if count > 0:
            print(f"  {cat:20} : {count:3} —Ç–µ–∫—Å—Ç–æ–≤")

    print(f"\n  {'–í–°–ï–ì–û':20} : {total:3} —Ç–µ–∫—Å—Ç–æ–≤")

    # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–∞ –≤ Markdown
    print("\nüìù –ì–µ–Ω–µ—Ä–∞—Ü–∏—è Markdown –æ—Ç—á–µ—Ç–∞...")
    korean_data = data.get('korean', {})
    markdown_report = generate_markdown_report(catalog, korean_data)

    with open('texts-catalog.md', 'w', encoding='utf-8') as f:
        f.write(markdown_report)

    print(f"‚úÖ Markdown –æ—Ç—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω: texts-catalog.md")

    # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è CSV –∫–∞—Ç–∞–ª–æ–≥–∞
    print("üìä –ì–µ–Ω–µ—Ä–∞—Ü–∏—è CSV –∫–∞—Ç–∞–ª–æ–≥–∞...")
    csv_catalog = generate_csv_catalog(catalog)

    with open('texts-catalog.csv', 'w', encoding='utf-8') as f:
        f.write(csv_catalog)

    print(f"‚úÖ CSV –∫–∞—Ç–∞–ª–æ–≥ —Å–æ—Ö—Ä–∞–Ω–µ–Ω: texts-catalog.csv")

    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ JSON
    print("üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ JSON...")
    with open('texts-catalog.json', 'w', encoding='utf-8') as f:
        json.dump(catalog, f, ensure_ascii=False, indent=2)

    print(f"‚úÖ JSON –∫–∞—Ç–∞–ª–æ–≥ —Å–æ—Ö—Ä–∞–Ω–µ–Ω: texts-catalog.json")

    print("\n‚ú® –ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω!")
    print(f"\n–°–æ–∑–¥–∞–Ω–æ 3 —Ñ–∞–π–ª–∞:")
    print(f"  - texts-catalog.md   (Markdown –æ—Ç—á–µ—Ç)")
    print(f"  - texts-catalog.csv  (CSV —Ç–∞–±–ª–∏—Ü–∞)")
    print(f"  - texts-catalog.json (JSON —Å—Ç—Ä—É–∫—Ç—É—Ä–∞)")

if __name__ == '__main__':
    main()
